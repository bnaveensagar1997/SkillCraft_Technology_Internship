{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6999dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e515c0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (5.29.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (75.8.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\navee\\onedrive\\documents\\miniproject\\.conda\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle\n",
    "\n",
    "def download_dataset():\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    print(\"[INFO] Downloading dataset from Kaggle...\")\n",
    "    api.competition_download_file('dogs-vs-cats', 'train.zip', path='data')\n",
    "\n",
    "    with zipfile.ZipFile('data/train.zip', 'r') as zip_ref:\n",
    "        print(\"[INFO] Extracting images...\")\n",
    "        zip_ref.extractall('data/train')\n",
    "    os.remove('data/train.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbc624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_dir, img_size=64, limit=2000):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    files = os.listdir(image_dir)\n",
    "    files = [f for f in files if f.endswith('.jpg')][:limit]\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        label = 0 if 'cat' in file else 1\n",
    "        img_path = os.path.join(image_dir, file)\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            data.append(img.flatten())\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {file} -> {e}\")\n",
    "\n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba1d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X, y):\n",
    "    print(\"[INFO] Splitting and scaling data...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    print(\"[INFO] Training SVM classifier...\")\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_dir = 'data/train/train'\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        # Upload kaggle.json and move it to the correct location\n",
    "        from pathlib import Path\n",
    "\n",
    "        kaggle_dir = Path.home() / \".kaggle\"\n",
    "        kaggle_dir.mkdir(exist_ok=True)\n",
    "        import shutil\n",
    "\n",
    "        from IPython.display import display\n",
    "        import ipywidgets as widgets\n",
    "\n",
    "        uploader = widgets.FileUpload(accept='.json', multiple=False)\n",
    "        display(uploader)\n",
    "\n",
    "        print(\"Please upload your kaggle.json file using the widget above.\")\n",
    "\n",
    "        # Wait for the user to upload the file\n",
    "        import time\n",
    "        while len(uploader.value) == 0:\n",
    "            time.sleep(1)\n",
    "\n",
    "        for filename, fileinfo in uploader.value.items():\n",
    "            with open(kaggle_dir / \"kaggle.json\", \"wb\") as f:\n",
    "                f.write(fileinfo['content'])\n",
    "        os.chmod(kaggle_dir / \"kaggle.json\", 0o600)\n",
    "\n",
    "        download_dataset()\n",
    "\n",
    "    print(\"[INFO] Loading image data...\")\n",
    "    X, y = load_images(data_dir, img_size=64, limit=2000)\n",
    "\n",
    "    print(\"[INFO] Training model...\")\n",
    "    train_svm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad127d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
